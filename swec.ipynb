{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# TODO:\r\n",
    "# GRAD-CAM\r\n",
    "# data visualization DONE\r\n",
    "# LSTM based model DONE\r\n",
    "# standardization and normalization (either based on training or individually) DONE\r\n",
    "# image based CNN IN PROGRESS\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import shutil\r\n",
    "import os\r\n",
    "import pickle\r\n",
    "from scipy.signal import stft"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# CNN class\r\n",
    "# TODO: some hardcoded numbers\r\n",
    "class CNN(nn.Module):\r\n",
    "    def __init__(self, input_channels=1, conv_channels=(3, 10), kernel=(5, 5), dropout=0.0):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = nn.Conv2d(input_channels, conv_channels[0], kernel[0])\r\n",
    "        self.pool = nn.MaxPool2d(2, 2)\r\n",
    "        self.conv2 = nn.Conv2d(conv_channels[0], conv_channels[1], kernel[1])\r\n",
    "        self.fc1 = nn.Linear(58*conv_channels[1], 120) # 5: 58, 7: \r\n",
    "        self.fc2 = nn.Linear(120, 84)\r\n",
    "        self.fc3 = nn.Linear(84, 2)\r\n",
    "        self.dropout1d = nn.Dropout(p=dropout)\r\n",
    "        self.dropout2d = nn.Dropout2d(p=dropout)\r\n",
    "        self.batchnorm1 = nn.BatchNorm2d(input_channels)\r\n",
    "        self.batchnorm2 = nn.BatchNorm2d(conv_channels[0])\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.batchnorm1(x)\r\n",
    "        x = self.pool(F.relu(self.conv1(x)))\r\n",
    "        # print(x.shape)\r\n",
    "        # x = self.dropout2d(x)\r\n",
    "        x = self.batchnorm2(x)\r\n",
    "        x = self.pool(F.relu(self.conv2(x)))\r\n",
    "        # print(x.shape)\r\n",
    "        # x = self.dropout2d(x)\r\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\r\n",
    "        # print(x.shape)\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = self.dropout1d(x)\r\n",
    "        x = F.relu(self.fc2(x))\r\n",
    "        x = self.fc3(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from swec_utils import training_model\r\n",
    "def grid_search(epochs, device, weights, train_loader, val_loader, dtype, kernel_sizes, n_filters, dropouts, save_path, plot_results=False):\r\n",
    "    sensitivity = []\r\n",
    "    specificity = []\r\n",
    "    auc = []\r\n",
    "    f1 = []\r\n",
    "    pr_auc = []\r\n",
    "    for k in kernel_sizes:\r\n",
    "        for f in n_filters:\r\n",
    "            for d in dropouts:\r\n",
    "                print(f\"Training model with kernel size = {k}, filter_sizes = {f}, dropout = {d}.\")\r\n",
    "                model = CNN(input_channels=next(iter(train_loader))[0].shape[1], conv_channels=f, kernel=(k, k), dropout=d)\r\n",
    "                model.to(numpy_to_torch_dtype_dict[dtype])\r\n",
    "                t_res, v_res = training_model(model, epochs, device, weights, train_loader, val_loader, dtype, plot_results=plot_results)\r\n",
    "                sensitivity.append(v_res.sen[-1])\r\n",
    "                specificity.append(v_res.spe[-1])\r\n",
    "                auc.append(v_res.auc[-1])\r\n",
    "                f1.append(v_res.f1[-1])\r\n",
    "                pr_auc.append(v_res.pr_auc[-1])\r\n",
    "                if (save_path):\r\n",
    "                    print(\"Saving model\")\r\n",
    "                    save_path += 'CNN_k' + str(k) + '_f' + str(f[0]) + '_' + str(f[1]) + '_d' + str(d).replace('.', '')\r\n",
    "                    torch.save(model.state_dict(), save_path)\r\n",
    "    \r\n",
    "    return sensitivity, specificity, auc, f1, pr_auc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def channel_selection(subject_path, seq_duration, sph, pil, distance, dtype, n_channels, **kwargs):\r\n",
    "    seed = 0\r\n",
    "    results_list = []\r\n",
    "    for channel in range(n_channels):\r\n",
    "        print(f\"Channel {channel}.\")\r\n",
    "        segments, labels, fs = load_data(subject_path, seq_duration, sph, pil, distance, channels=[channel], dtype=dtype)\r\n",
    "\r\n",
    "        segments_t = np.transpose(segments, (0, 2, 1))\r\n",
    "        print(segments_t.shape)\r\n",
    "        print(segments_t.dtype)\r\n",
    "        Zxx = np.zeros((segments_t.shape[0], segments_t.shape[1], 129, 21), dtype=dtype)\r\n",
    "\r\n",
    "        _, _, Zxx = stft(segments_t, fs=fs)\r\n",
    "\r\n",
    "        BATCH = 512\r\n",
    "        EPOCHS = 250\r\n",
    "        use_cuda = True\r\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n",
    "\r\n",
    "        X, X_test, Y, Y_test = train_test_split(Zxx, labels, test_size=0.2, stratify=labels, random_state=seed)\r\n",
    "\r\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=seed)\r\n",
    "\r\n",
    "        weights = torch.tensor(compute_class_weight(class_weight='balanced', classes=np.unique(Y_train), y=Y_train), dtype=dtype, device=device)\r\n",
    "        # weights = torch.tensor([1, 1], dtype=torch.float32, device=device)\r\n",
    "\r\n",
    "        # convert dataset to Dataloader\r\n",
    "        train_dataset = STFTDataset(X_train, Y_train)\r\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH)\r\n",
    "        val_dataset = STFTDataset(X_val, Y_val)\r\n",
    "        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH)\r\n",
    "\r\n",
    "        results = grid_search(EPOCHS, device, weights, train_loader, val_loader, dtype, **kwargs, save_path='')\r\n",
    "        results_list.append(results)\r\n",
    "\r\n",
    "    return results_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def copy_subject(src, dst):\r\n",
    "    src_files = os.listdir(src)\r\n",
    "    for file_name in src_files:\r\n",
    "        full_file_name = os.path.join(src, file_name)\r\n",
    "        if os.path.isfile(full_file_name):\r\n",
    "            shutil.copy(full_file_name, dst)\r\n",
    "            print(file_name)\r\n",
    "\r\n",
    "subject = 'ID03'\r\n",
    "src = 'D:/research/swec/' + subject\r\n",
    "dst = './swec/' + subject\r\n",
    "data_path = './swec/' + subject + '/data.p'\r\n",
    "if (not os.path.exists(data_path)):\r\n",
    "    if (len(os.listdir(dst)) == 0):\r\n",
    "        copy_subject(src, dst)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 1: 4\r\n",
    "# 2: 7\r\n",
    "# 3: 2\r\n",
    "from swec_utils import load_data\r\n",
    "subject_path = './swec/' + subject + '/' + subject\r\n",
    "seq_duration = 5\r\n",
    "sph = 300\r\n",
    "pil = 3600\r\n",
    "distance = 3600 * 24 * 2\r\n",
    "\r\n",
    "dtype = np.float16\r\n",
    "\r\n",
    "if (os.path.exists(data_path)):\r\n",
    "    print(f\"Data already processed at {data_path}\")\r\n",
    "    data = pickle.load(open(data_path, 'rb'))\r\n",
    "    Zxx, labels = data\r\n",
    "else:\r\n",
    "    segments, labels, fs = load_data(subject_path, seq_duration, sph, pil, distance, channels=[], dtype=dtype)\r\n",
    "\r\n",
    "    segments_t = np.transpose(segments, (0, 2, 1))\r\n",
    "    print(segments_t.shape)\r\n",
    "    print(segments_t.dtype)\r\n",
    "    Zxx = np.zeros((segments_t.shape[0], segments_t.shape[1], 129, 21), dtype=dtype)\r\n",
    "\r\n",
    "    for i in range(segments_t.shape[1]):\r\n",
    "        print(i)\r\n",
    "        _, _, Zxx[:, i, :] = stft(segments_t[:,i,:], fs=fs)\r\n",
    "    print(Zxx.shape)\r\n",
    "\r\n",
    "    data = (Zxx, labels)\r\n",
    "    pickle.dump(data, open(data_path, 'wb'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data already processed at ./swec/ID03/data.p\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "# u and s must be vectors of length data.shape[1]\r\n",
    "def standardize(data, u, s):\r\n",
    "    std_data = np.zeros(data.shape, dtype=np.float16)\r\n",
    "    for i in range(data.shape[1]):\r\n",
    "        std_data[:,i] = (data[:,i] - u[i]) / s[i]\r\n",
    "    return std_data\r\n",
    "\r\n",
    "def compute_u_s(data):\r\n",
    "    u, s = [], []\r\n",
    "    for i in range(data.shape[1]):\r\n",
    "        u.append(np.mean(data[:,i].astype(np.float64)))\r\n",
    "        s.append(np.std(data[:,i].astype(np.float64)))\r\n",
    "    return u, s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from swec_utils import STFTDataset, numpy_to_torch_dtype_dict\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.utils.class_weight import compute_class_weight\r\n",
    "\r\n",
    "BATCH = 512\r\n",
    "EPOCHS = 100\r\n",
    "use_cuda = True\r\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n",
    "\r\n",
    "X, X_test, Y, Y_test = train_test_split(Zxx, labels, test_size=0.2, stratify=labels, random_state=0)\r\n",
    "\r\n",
    "del Zxx, labels\r\n",
    "\r\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=0)\r\n",
    "\r\n",
    "del X, Y\r\n",
    "\r\n",
    "# standardize\r\n",
    "# u, s = compute_u_s(X_train)\r\n",
    "# X_train = standardize(X_train, u, s)\r\n",
    "# X_val = standardize(X_val, u, s)\r\n",
    "\r\n",
    "# normalize\r\n",
    "# for i in range(X_train.shape[1]):\r\n",
    "#     X_min = np.min(X_train[:,i])\r\n",
    "#     X_max = np.max(X_train[:,i])\r\n",
    "#     X_train[:,i] = (X_train[:,i] - X_min) / (X_max - X_min)\r\n",
    "#     X_val[:,i] = (X_val[:,i] - X_min) / (X_max - X_min)\r\n",
    "\r\n",
    "weights = torch.tensor(compute_class_weight(class_weight='balanced', classes=np.unique(Y_train), y=Y_train), dtype=numpy_to_torch_dtype_dict[dtype], device=device)\r\n",
    "\r\n",
    "# convert dataset to Dataloader\r\n",
    "train_dataset = STFTDataset(X_train, Y_train, dtype=dtype)\r\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH)\r\n",
    "val_dataset = STFTDataset(X_val, Y_val, dtype=dtype)\r\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH)\r\n",
    "\r\n",
    "save_path = 'models/' + subject + '/'\r\n",
    "# save_path = '' # comment out this line if you want to save\r\n",
    "results = grid_search(EPOCHS, device, weights, train_loader, val_loader, dtype, [5], [(5, 5)], [0.5], save_path=save_path, plot_results=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training model with kernel size = 5, filter_sizes = (5, 5), dropout = 0.5.\n",
      "Epoch 10.\n",
      "Epoch 20.\n",
      "Epoch 30.\n",
      "Epoch 40.\n",
      "Epoch 50.\n",
      "Epoch 60.\n",
      "Epoch 70.\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from swec_utils import to_numpy\r\n",
    "\r\n",
    "# convert dataset to Dataloader\r\n",
    "test_dataset = STFTDataset(X_test, Y_test, dtype=dtype)\r\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH)\r\n",
    "\r\n",
    "# retrieve model from save\r\n",
    "model = CNN(input_channels=next(iter(test_loader))[0].shape[1], kernel=(5, 5), conv_channels=(5, 5), dropout=0.5)\r\n",
    "path = './models/' + subject + '/CNN_k5_f5_5_d05'\r\n",
    "model.load_state_dict(torch.load(path))\r\n",
    "\r\n",
    "model.to(numpy_to_torch_dtype_dict[dtype])\r\n",
    "model.to(device)\r\n",
    "model.eval()\r\n",
    "\r\n",
    "pred_list = np.zeros((len(test_loader.dataset), 2))\r\n",
    "true_list = np.zeros(len(test_loader.dataset))\r\n",
    "i = 0\r\n",
    "with torch.no_grad():\r\n",
    "    for data, target in test_loader:\r\n",
    "        data, target = data.to(device), target.to(device)\r\n",
    "\r\n",
    "        output = model(data)\r\n",
    "        pred_list[i:i+len(data)] = to_numpy(output)\r\n",
    "        true_list[i:i+len(data)] = to_numpy(target)\r\n",
    "        i += len(data)\r\n",
    "\r\n",
    "y_true = true_list\r\n",
    "y_pred = pred_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, roc_curve, precision_recall_curve, confusion_matrix, auc, average_precision_score, plot_precision_recall_curve\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from swec_utils import evaluate_performance\r\n",
    "\r\n",
    "print(y_true.shape)\r\n",
    "print(y_pred.shape)\r\n",
    "\r\n",
    "sensitivity, specificity, roc_auc, f1_score, pr_auc = evaluate_performance(y_pred, y_true)\r\n",
    "\r\n",
    "print(\"Sensitivity: \" + str(sensitivity))\r\n",
    "print(\"Specificity: \" + str(specificity))\r\n",
    "print(\"F1 Score: \" + str(f1_score))\r\n",
    "print(\"AUC: \" + str(roc_auc))\r\n",
    "print(\"PR AUC: \" + str(pr_auc))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from pytorch_grad_cam import GradCAM\r\n",
    "# from pytorch_grad_cam.utils.image import show_cam_on_image\r\n",
    "\r\n",
    "# target_layer = next(model.children())\r\n",
    "# cam = GradCAM(model=model, target_layer=target_layer, use_cuda=True)\r\n",
    "\r\n",
    "# input_tensor = torch.tensor(X_test[0:1], dtype=numpy_to_torch_dtype_dict[dtype], device=device)\r\n",
    "# target_category = torch.tensor(Y_test[0:1], dtype=torch.long, device=device)\r\n",
    "# grayscale_cam = cam(input_tensor=input_tensor, target_category=target_category)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(X_val[0,:,0])\r\n",
    "print(X_val[0,:,-1])\r\n",
    "print(X_val[-1,:,0])\r\n",
    "print(X_val[-1,:,-1])\r\n",
    "print(np.count_nonzero(Y_val == 1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(X_val[np.where(Y_val == 1)[0][0],:,0])\n",
    "print(X_val[np.where(Y_val == 1)[0][0],:,-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d82368bffa793200a131ac8e557b008ccb2806dd7ba8623e02f987c04e882c79"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}